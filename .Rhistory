learn_rate = 0.01,
col_sample_rate = 0.7,
nfolds = nfolds,
seed = 1,
keep_cross_validation_predictions = TRUE)
library(data.table)
library(caret)
library(dplyr)
library(purrr)
setwd("C:/Users/jaycb/Desktop/Water Project")
train_ind=read.csv("train_ind.csv")
test_ind=read.csv("test_ind.csv")
names(train_ind)
str(train_ind)
train_lab=read.csv("train_lab.csv")
train_ind$istr="Yes"
test_ind$istr="No"
train_ind=rbind(train_ind,test_ind)
train_ind$date_recorded=as.character(train_ind$date_recorded)
train_ind$year=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[1])))
train_ind$month=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[2])))
train_ind$day=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[3])))
train_ind$date_recorded=NULL
train_ind$ward=NULL
train_ind$funder=NULL
train_ind$scheme_name=NULL
train_ind$subvillage=NULL
train_ind$installer=NULL
train_ind$recorded_by=NULL
train_ind$region_code=as.factor(as.character(train_ind$region_code))
train_ind$district_code=as.factor(as.character(train_ind$district_code))
train_ind$construction_year=as.factor(as.character(train_ind$construction_year))
cnames=names(train_ind)
### XGBoost
library(xgboost)
library(caret)
train<-train_ind[train_ind$istr=="Yes",]
train$target<-map_chr(train_lab$status_group,function(x) c("F","FNR","NF")[x])
train$istr=NULL
test<- train_ind[train_ind$istr=="No",]
test$istr=NULL
nfolds <- 5
library(h2o)
h2o.init()
h20.shutdown()
h2o.shutdown()
?h2o.init
library(h2o)
h2o.init(max_mem_size = "7g")
library(sparklyr)
library(rsparkling)
sc <- spark_connect(master = "local")
train_tbl<-copy_to(sc,train)
test_tbl<-copy_to(sc,test)
training <- as_h2o_frame(sc, train_tbl, strict_version_check = FALSE)
training <- as_h2o_frame(sc, train_tbl, strict_version_check = FALSE)
testing <- as_h2o_frame(sc, test_tbl, strict_version_check = FALSE)
y <- "target"
x <- setdiff(names(training), y)
training[,y] <- as.factor(training[,y])
c_names<-names(training)
for (c in 1:length(c_names)){
m=c_names[c]
if (is.character(training[,m])){
training[,m] <- as.factor(training[,m])
}
}
?h2o.splitFrame
splits <- h2o.splitFrame(training,ratios = 0.90, seed = 1)
dim(splits[1])
dim(splits[[1])
dim(splits[[1]])
dim(splits[[2]])
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 750,
max_depth = 15,
learn_rate = 0.01,
col_sample_rate = 0.7,
nfolds = nfolds,
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
seed = 1,
keep_cross_validation_predictions = TRUE)
h2o.confusionMatrix(gbm_model, valid = TRUE)
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 1,
activation = "Rectifier",
hidden = c(4, 2,4),
input_dropout_ratio = 0.7,
keep_cross_validation_predictions = TRUE,
nfolds = nfolds)
h2o.performance(dl_fit, newdata = splits[[2]])
library(h2oEnsemble)
rf1 <- h2o.randomForest(x = x, y = y, #distribution = "bernoulli",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
nfolds = nfolds,
#fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE)
h2o.confusionMatrix(rf1, valid = TRUE)
pred = h2o.predict(object = rf1, newdata = testing)
predicted<- as.data.frame(pred$predict)
sub=read.csv("SubmissionFormat.csv")
sub$status_group=map(predicted['predict'],function(x) c("functional","functional needs repair","non functional")[x])$predict
write.csv(sub, file = "water_rf.csv", row.names = F)
library(h2oEnsemble)
models <- list(dl_fit,gbm_model,rf1)
metalearner <- "h2o.rf.wrapper"
stack <- h2o.stack(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
seed = 1,
keep_cross_validation_predictions = TRUE,
fold_assingment == Modulo)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
seed = 1,
keep_cross_validation_predictions = TRUE,
fold_assingment == "Modulo")
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment == "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = training,#splits[[1]],
#validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment == "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = training,#splits[[1]],
#validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment = "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment = "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment =+ "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 10,
max_depth = 3,
learn_rate = 0.4,
col_sample_rate = 0.7,
nfolds = nfolds,
fold_assingment == "Modulo",
seed = 1,
keep_cross_validation_predictions = TRUE)
rf1 <- h2o.randomForest(x = x, y = y, #distribution = "bernoulli",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
nfolds = nfolds,
#fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE)
h2o.confusionMatrix(rf1, valid = TRUE)
models <- list(dl_fit,gbm_model,rf1)
metalearner <- "h2o.rf.wrapper"
stack <- h2o.stack(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = training,
#distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE,
seed = 1)
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = training,
ntrees = 10,
nfolds = nfolds,
fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE,
seed = 1)
ensemble <- h2o.stackedEnsemble(x = x,
y = y,
training_frame = train,
model_id = "my_ensemble_binomial",
base_models = list(my_gbm@model_id, my_rf@model_id))
ensemble <- h2o.stack(x = x,
y = y,
training_frame = train,
model_id = "my_ensemble_binomial",
base_models = list(my_gbm@model_id, my_rf@model_id))
ensemble <- h2o.stack(x = x,
y = y,
training_frame = train,
model_id = "my_ensemble_binomial",
base_models = list(my_gbm@model_id, my_rf@model_id))
ensemble <- h2o.stack(x = x,
y = y,
training_frame = train,
model_id = "my_ensemble_binomial",
base_models = list(my_gbm, my_rf))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
install.packages(c("curl", "h2o", "jsonlite", "NLP", "pbkrtest", "Rcpp", "RcppEigen", "readr", "rmarkdown", "shiny", "SparseM", "stm", "stringi", "stringr", "tibble", "tm", "topicmodels"))
models <- list(my_gbm, my_rf)
metalearner <- "h2o.rf.wrapper"
stack <- h2o.stack(models = models,
response_frame = train[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
library(h2oEnsemble)
install.packages("jsonlite")
library(h2oEnsemble)
models <- list(my_gbm, my_rf)
metalearner <- "h2o.rf.wrapper"
stack <- h2o.stack(models = models,
response_frame = train[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
stack <- h2o.stack(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
nfolds <- 5
library(h2o)
h2o.init(max_mem_size = "7g")
library(sparklyr)
library(rsparkling)
stack <- h2o.stack(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
library(data.table)
library(caret)
library(dplyr)
library(purrr)
setwd("C:/Users/jaycb/Desktop/Water Project")
train_ind=read.csv("train_ind.csv")
test_ind=read.csv("test_ind.csv")
names(train_ind)
str(train_ind)
train_lab=read.csv("train_lab.csv")
train_ind$istr="Yes"
test_ind$istr="No"
train_ind=rbind(train_ind,test_ind)
train_ind$date_recorded=as.character(train_ind$date_recorded)
train_ind$year=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[1])))
train_ind$month=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[2])))
train_ind$day=as.factor(unlist(map(train_ind$date_recorded, function(x) unlist(strsplit(x,"-"))[3])))
train_ind$date_recorded=NULL
train_ind$ward=NULL
train_ind$funder=NULL
train_ind$scheme_name=NULL
train_ind$subvillage=NULL
train_ind$installer=NULL
train_ind$recorded_by=NULL
train_ind$region_code=as.factor(as.character(train_ind$region_code))
train_ind$district_code=as.factor(as.character(train_ind$district_code))
train_ind$construction_year=as.factor(as.character(train_ind$construction_year))
cnames=names(train_ind)
### XGBoost
library(xgboost)
library(caret)
train<-train_ind[train_ind$istr=="Yes",]
train$target<-map_chr(train_lab$status_group,function(x) c("F","FNR","NF")[x])
train$istr=NULL
test<- train_ind[train_ind$istr=="No",]
test$istr=NULL
nfolds <- 5
library(h2o)
h2o.init(max_mem_size = "7g")
library(sparklyr)
library(rsparkling)
sc <- spark_connect(master = "local")
train_tbl<-copy_to(sc,train)
test_tbl<-copy_to(sc,test)
training <- as_h2o_frame(sc, train_tbl, strict_version_check = FALSE)
testing <- as_h2o_frame(sc, test_tbl, strict_version_check = FALSE)
y <- "target"
x <- setdiff(names(training), y)
training[,y] <- as.factor(training[,y])
c_names<-names(training)
for (c in 1:length(c_names)){
m=c_names[c]
if (is.character(training[,m])){
training[,m] <- as.factor(training[,m])
}
}
library(h2oEnsemble)
my_gbm <- h2o.gbm(x = x,
y = y,
training_frame = training,
#distribution = "bernoulli",
ntrees = 10,
max_depth = 3,
min_rows = 2,
learn_rate = 0.2,
nfolds = nfolds,
fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE,
seed = 1)
my_rf <- h2o.randomForest(x = x,
y = y,
training_frame = training,
ntrees = 10,
nfolds = nfolds,
fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE,
seed = 1)
models <- list(my_gbm, my_rf)
metalearner <- "h2o.rf.wrapper"
stack <- h2o.stack(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
stack <- h2o.ensemble(models = models,
response_frame = training[,y],
metalearner = metalearner,
seed = 1,
keep_levelone_data = TRUE)
labels <- train$target
new_tr <- model.matrix(~.+0,data = train[,-c("target"),with=F])
new_tr <- model.matrix(~.+0,data = train[,-c("target")])
new_tr <- model.matrix(~.+0,data = train[,-target])
train<-train_ind[train_ind$istr=="Yes",]
target<-map_chr(train_lab$status_group,function(x) c("F","FNR","NF")[x])
train$istr=NULL
test<- train_ind[train_ind$istr=="No",]
test$istr=NULL
dtrain <- xgb.DMatrix(data = train,label = target)
dtrain <- xgb.DMatrix(data = train,label = as.data.frame(target))
dtrain <- xgb.DMatrix(data = train,label = labels)
new_tr <- model.matrix(~.+0,data = train[,-train$target])
new_tr <- model.matrix(~.+0,data = train)
new_tr <- model.matrix(~.+0,data = data.table(train))
data_test.noID<-subset(test, select = -id)
data_train<-subset(train, select = c(-id,-status_group))
data_train<-subset(train, select = c(-id,-target))
train<-train_ind[train_ind$istr=="Yes",]
train$target<-map_chr(train_lab$status_group,function(x) c("F","FNR","NF")[x])
train$istr=NULL
test<- train_ind[train_ind$istr=="No",]
test$istr=NULL
data_test.noID<-subset(test, select = -id)
data_train<-subset(train, select = c(-id,-target))
data_test.noID <- as.matrix(as.data.frame(lapply(data_test.noID, as.numeric)))
data_train <- as.matrix(as.data.frame(lapply(data_train, as.numeric)))
label<-as.numeric(train$target)
dim(label)
label[1]
label<-train$target
label[1]
str(label)
table(label)
train.DMatrix <- xgb.DMatrix(data = data_train,label = label, missing = NA)
label<-map(train$target, function(x) c(1,2,3)[x])
label[1]
label<-map(train$target, function(x) c("1","2","3")[x])
label[1]
train$target
label<-map(train$target, function(x) c("1","2","3")[x])
label
label<-map(train_lab$status_group, function(x) c("1","2","3")[x])
label[1]
label<-map(train_lab$status_group,as.numeric())
label<-map(train_lab$status_group,as.numeric)
label[1]
label<-unlist(map(train_lab$status_group,as.numeric))
train.DMatrix <- xgb.DMatrix(data = data_train,label = label, missing = NA)
xgb.tab = xgb.cv(data = train.DMatrix, objective = "multi:softmax", booster = "gbtree",
nrounds = 500, nfold = 4, early.stop.round = 10, num_class = 4, maximize = FALSE,
evaluation = "merror", eta = .2, max_depth = 12, colsample_bytree = .4)
predict <- predict(model,data_test.noID)
predict <- predict(xgb.tab,data_test.noID)
xgb.tab = xgboost(data = train.DMatrix, objective = "multi:softmax", booster = "gbtree",
nrounds = 500, nfold = 4, early.stop.round = 10, num_class = 4, maximize = FALSE,
evaluation = "merror", eta = .2, max_depth = 12, colsample_bytree = .4)
predict <- predict(xgb.tab,data_test.noID)
predict[predict==1]<-"functional"
predict[predict==2]<-"functional needs repair"
predict[predict==3]<-"non functional"
table(predict)
sub=read.csv("SubmissionFormat.csv")
sub$status_group=predicted['predict']
sub$status_group=predict['predict']
head(sub)
sub
sub$status_group=predict
head(sub)
sub
write.csv(sub, file = "water_xgb.csv", row.names = F)
glm_model <- h2o.glm(x = x,
y = y,
training_frame = training,
family = "multinomial",
lambda_search = TRUE)
print(glm_model)
?h2o.randomForest
rf1 <- h2o.randomForest(x = x, y = y, #distribution = "bernoulli",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
ntrees = 1500,
max_depth = 25,
nfolds = nfolds,
#fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE)
rf1 <- h2o.randomForest(x = x, y = y, #distribution = "bernoulli",
training_frame = training,
#validation_frame = splits[[2]],
seed = 1,
ntrees = 1500,
max_depth = 25,
nfolds = nfolds,
#fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE)
rf1 <- h2o.randomForest(x = x, y = y, #distribution = "bernoulli",
training_frame = training,
#validation_frame = splits[[2]],
seed = 1,
ntrees = 2000,
max_depth = 15,
nfolds = nfolds,
#fold_assignment = "Modulo",
keep_cross_validation_predictions = TRUE)
